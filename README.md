# 🚀 TinyML: A Compact Revolution in Engineering AI  
**Workshop at MERCon 2025 – Moratuwa Engineering Research Conference**  

![MERCon Logo](images/logo2025.png)  
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)  

---

## 📖 About the Workshop  
As deep learning models grow in complexity, deploying them on **resource-constrained devices** requires **model optimization and efficient architectures**.  

In this workshop, you’ll learn:  
- 🔹 **Model compression** – pruning, quantization-aware training, post-training quantization, knowledge distillation  
- 🔹 **Efficient architectures** – improving speed, memory, and energy savings  
- 🔹 **Deployment** – running AI models on embedded & mobile devices  

This is a **hands-on and theory-integrated workshop** with a focus on **practical deployment** of TinyML in engineering applications.  

---

## 📂 Repository Structure  
Each session has its **own folder** containing:  
- `slides/` – PDF or PPTX slides  
- `notebooks/` – Colab or Jupyter notebooks for hands-on exercises  
- `models/` – Pre-trained `.tflite` models (if applicable)  


---

## 📅 Workshop Agenda with Resources  
| Time | Topic | Presenter | Resources |
|------|-------|-----------|-----------|
| **1:00 – 1:05 PM** | Intro to Panel | Dr. Dharshana | — |
| **1:05 – 1:15 PM** | Introduction to the Session | Asiri | [📄 Slides](01_Intro_to_TinyML/slides/) |
| **1:15 – 2:00 PM** | Wet TinyML | Dr. Samitha | [📄 Slides](01_Intro_to_TinyML/slides/) |
| **2:00 – 3:15 PM** | Model Compression Techniques | Dr. Dinuka | [📄 Slides](02_Model_Compression/slides/) / [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](02_Model_Compression/notebooks/model_compression.ipynb) |
| **3:15 – 3:30 PM** | ☕ Break | — | — |
| **3:30 – 4:10 PM** | Coding Session – Model Compression | Asiri | [📄 Slides](03_Coding_Model_Compression/slides/) / [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](03_Coding_Model_Compression/notebooks/model_compression_coding.ipynb) |
| **4:10 – 4:40 PM** | Architectural Improvements | Sanka | [📄 Slides](04_Architectural_Improvements/slides/) |
| **4:40 – 5:10 PM** | Theoretical Session – DeepSets | Asiri | [📄 Slides](05_DeepSets_Theory/slides/) / [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](05_DeepSets_Theory/notebooks/deepsets_theory.ipynb) |
| **5:10 – 5:30 PM** | Energy-Efficient Architectures | Dr. Mahima | [📄 Slides](06_Energy_Efficient_Architectures/slides/) |

---

## 📱 Interactive Resources  
- **Google Colab** – Instant cloud execution of coding exercises (no local setup)  
- **TFLite Models** – Deploy models on microcontrollers and mobile devices  

---

## 👨‍🏫 Facilitators  
- **Dr. Samitha Somathilaka** – University of Nebraska–Lincoln  
- **Dr. Dinuka Sahabandu** – University of Washington  
- **Dr. Mahima Weerasinghe** – SLIIT  
- **Mr. Asiri Gawesha** – SLIIT  
- **Mr. Sanka Mohottala** – SLIIT  

---

## 🛠 How to Use This Repository  
1. Pick the **session folder** you’re interested in.  
2. Click the **Colab badge** to launch the notebook instantly.  
3. Review the **slides** for theory before coding.  
4. Deploy `.tflite` models to supported devices (if available).  

---

## 📜 License  
All materials in this repository are licensed under the [MIT License](LICENSE) unless otherwise stated.  

---

> 💡 *This repository is maintained by the TinyML Workshop Team as part of MERCon 2025.*
